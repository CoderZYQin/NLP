{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./comment-classification/ai_challenger_sentiment_analysis_trainingset_20180816/sentiment_analysis_trainingset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>location_traffic_convenience</th>\n",
       "      <th>location_distance_from_business_district</th>\n",
       "      <th>location_easy_to_find</th>\n",
       "      <th>service_wait_time</th>\n",
       "      <th>service_waiters_attitude</th>\n",
       "      <th>service_parking_convenience</th>\n",
       "      <th>service_serving_speed</th>\n",
       "      <th>price_level</th>\n",
       "      <th>...</th>\n",
       "      <th>environment_decoration</th>\n",
       "      <th>environment_noise</th>\n",
       "      <th>environment_space</th>\n",
       "      <th>environment_cleaness</th>\n",
       "      <th>dish_portion</th>\n",
       "      <th>dish_taste</th>\n",
       "      <th>dish_look</th>\n",
       "      <th>dish_recommendation</th>\n",
       "      <th>others_overall_experience</th>\n",
       "      <th>others_willing_to_consume_again</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            content  \\\n",
       "0   0  \"吼吼吼，萌死人的棒棒糖，中了大众点评的霸王餐，太可爱了。一直就好奇这个棒棒糖是怎么个东西，...   \n",
       "\n",
       "   location_traffic_convenience  location_distance_from_business_district  \\\n",
       "0                            -2                                        -2   \n",
       "\n",
       "   location_easy_to_find  service_wait_time  service_waiters_attitude  \\\n",
       "0                     -2                 -2                         1   \n",
       "\n",
       "   service_parking_convenience  service_serving_speed  price_level  \\\n",
       "0                           -2                     -2           -2   \n",
       "\n",
       "                ...                 environment_decoration  environment_noise  \\\n",
       "0               ...                                     -2                 -2   \n",
       "\n",
       "   environment_space  environment_cleaness  dish_portion  dish_taste  \\\n",
       "0                 -2                    -2            -2          -2   \n",
       "\n",
       "   dish_look  dish_recommendation  others_overall_experience  \\\n",
       "0          1                   -2                          1   \n",
       "\n",
       "   others_willing_to_consume_again  \n",
       "0                               -2  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(data,name): return pd.get_dummies(data[name], prefix=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_dummies(data):\n",
    "    columns_names = data.columns.values[2:]\n",
    "    \n",
    "    concat_list = [data]\n",
    "    \n",
    "    for name in columns_names:\n",
    "        concat_list.append(get_dummies(data, name))\n",
    "        \n",
    "    return pd.concat(concat_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  handle_dummies(train).iloc[:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 102)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contents = train['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string): return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/_8/f14fxxnn7w13cd0l5x9hl4bm0000gn/T/jieba.cache\n",
      "Loading model cost 0.790 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "all_contents = [' '.join(cut(s)) for s in all_contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" 吼吼 吼 ， 萌死 人 的 棒棒糖 ， 中 了 大众 点评 的 霸王餐 ， 太 可爱 了 。 一直 就 好奇 这个 棒棒糖 是 怎么 个 东西 ， 大众 点评 给 了 我 这个 土老冒 一个 见识 的 机会 。 看 介绍 棒棒糖 是 用 德国 糖 做 的 ， 不会 很甜 ， 中间 的 照片 是 糯米 的 ， 能 食用 ， 真是太 高端 大气 上档次 了 ， 还 可以 买 蝴蝶结 扎口 ， 送人 可以 买 礼盒 。 我 是 先 打 的 卖家 电话 ， 加 了 微信 ， 给 卖家 传 的 照片 。 等 了 几天 ， 卖家 就 告诉 我 可以 取货 了 ， 去 大官 屯 那取 的 。 虽然 连 卖家 的 面 都 没 见到 ， 但是 还是 谢谢 卖家 送 我 这么 可爱 的 东西 ， 太 喜欢 了 ， 这 哪 舍得吃 啊 。 \"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "maxlen = 100\n",
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(all_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[train.columns[-80:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, 300, input_length=maxlen)(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(GRU(80, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(80, activation=\"sigmoid\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 100, 300)     1500000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 100, 300)     0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 100, 160)     182880      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 160)          0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 160)          0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 320)          0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           25680       concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,708,560\n",
      "Trainable params: 1,708,560\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tra, X_val, y_tra, y_val = train_test_split(X_train, y_train, train_size=0.9, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      " - 248s - loss: 0.3281 - acc: 0.8642 - val_loss: 0.3019 - val_acc: 0.8785\n",
      "Epoch 2/10\n",
      " - 251s - loss: 0.2957 - acc: 0.8810 - val_loss: 0.2896 - val_acc: 0.8844\n",
      "Epoch 3/10\n",
      " - 282s - loss: 0.2827 - acc: 0.8868 - val_loss: 0.2825 - val_acc: 0.8877\n",
      "Epoch 4/10\n",
      " - 279s - loss: 0.2741 - acc: 0.8906 - val_loss: 0.2803 - val_acc: 0.8893\n",
      "Epoch 5/10\n",
      " - 261s - loss: 0.2671 - acc: 0.8934 - val_loss: 0.2779 - val_acc: 0.8900\n",
      "Epoch 6/10\n",
      " - 245s - loss: 0.2610 - acc: 0.8958 - val_loss: 0.2797 - val_acc: 0.8901\n",
      "Epoch 7/10\n",
      " - 246s - loss: 0.2553 - acc: 0.8982 - val_loss: 0.2801 - val_acc: 0.8897\n",
      "Epoch 8/10\n",
      " - 489s - loss: 0.2496 - acc: 0.9006 - val_loss: 0.2823 - val_acc: 0.8897\n",
      "Epoch 9/10\n",
      " - 246s - loss: 0.2441 - acc: 0.9029 - val_loss: 0.2847 - val_acc: 0.8882\n",
      "Epoch 10/10\n",
      " - 252s - loss: 0.2385 - acc: 0.9052 - val_loss: 0.2897 - val_acc: 0.8851\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 80)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.88027346e-01, 2.42944304e-02, 1.55577660e-02, 1.53742746e-01,\n",
       "       8.35472703e-01, 2.48388061e-03, 4.91097430e-03, 1.63792148e-01,\n",
       "       9.17777538e-01, 5.00423610e-02, 3.65001783e-02, 3.51194032e-02,\n",
       "       3.06623697e-01, 2.80836254e-01, 2.90861756e-01, 1.94561064e-01,\n",
       "       8.26987147e-01, 9.07066744e-03, 9.53930244e-02, 1.54305175e-01,\n",
       "       9.85910416e-01, 1.07142124e-02, 4.68213344e-03, 8.28887336e-03,\n",
       "       9.68940794e-01, 2.92383116e-02, 2.14965045e-02, 1.17693329e-02,\n",
       "       7.65157461e-01, 2.12375093e-02, 1.77859485e-01, 6.48354515e-02,\n",
       "       7.19269514e-01, 6.71135448e-03, 3.43208984e-02, 2.06883788e-01,\n",
       "       9.01179790e-01, 6.06599683e-03, 9.37790424e-02, 4.20628898e-02,\n",
       "       3.80705923e-01, 5.89910187e-02, 1.22798108e-01, 3.44277114e-01,\n",
       "       3.90029073e-01, 1.29778907e-01, 1.35557950e-01, 2.62189239e-01,\n",
       "       4.30190235e-01, 1.59292072e-01, 1.15669645e-01, 2.18376130e-01,\n",
       "       6.58969700e-01, 2.58027278e-02, 7.70675391e-02, 1.86372355e-01,\n",
       "       7.65441477e-01, 5.25216535e-02, 6.43392280e-02, 1.40756354e-01,\n",
       "       1.71508233e-03, 2.98897969e-03, 8.21035445e-01, 1.96368352e-01,\n",
       "       7.54116833e-01, 1.27050504e-02, 6.04898259e-02, 1.64800912e-01,\n",
       "       9.53794479e-01, 4.87687765e-03, 7.22708227e-03, 4.91418242e-02,\n",
       "       3.74745503e-02, 6.07844116e-03, 3.05628747e-01, 7.43892431e-01,\n",
       "       9.71330583e-01, 4.91771789e-04, 1.01386877e-02, 3.47242504e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kstone",
   "language": "python",
   "name": "kstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
